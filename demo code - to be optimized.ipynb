{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5. Machine Learning and Natural Language Processing\n",
    "\n",
    "OPIM 5894 Data Science with Python\n",
    "\n",
    "Name:   NetID:\n",
    "\n",
    "Discussed with: if any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "In this assignment, you are asked to predict genders of users using their public information on websites. In question 1, you are asked to predict gender using only usename. In question 2, you are asked to predict gender using the profile description of a user instead. Finally, you may combine all available information of users to make predictions. You may explore different models and different combination of features, as well as different ways to transform features, to achieve best performance. \n",
    "<br> <br>\n",
    "- It is recommended to use NLTK for this classification task, as the features stored in dictionary style can be easily extended. While scikit-learn is easier for Q2, it might not be that straightforward to combine different features in Q3. In addition, dealing with categorical variables can be a pain in scikit-learn. If you plan to use scikit-learn anyway, please read the following post: http://pbpython.com/categorical-encoding.html\n",
    "- While protyping, it is easier to stick to the Naive Bayes Classifier. Adding other classifiers once your code is bug-free.\n",
    "- Use cross validation on the training set to avoid over-fitting, though it is not guaranteed achieve that purpose.\n",
    "\n",
    "\n",
    "<br>\n",
    "This assignment involves the following challenges:\n",
    "- Construct features from strings (i.e., usernames)\n",
    "- Frequent use of zip() and zip(*) (see doc https://docs.python.org/3/library/functions.html)\n",
    "- Parsing a json style column into multiple columns\n",
    "- Merging different features into one feature set\n",
    "- Find appropriate models and features to improve prediction accuracy\n",
    "- Writing and debugging a lot of code\n",
    "<br><br>\n",
    "\n",
    "What to submit?\n",
    "- The predictions of 5 models on the test set (see a sample submission sample_submission.csv). Diverify your portfolio, as similar models may suffer from similar problems.\n",
    "- The notebook file (** please make sure that your code are sufficiently commented**)\n",
    "- In the end of the notebook file, briefly describe what you have done, which models work the best, and what findings you have.\n",
    "<br><br>\n",
    "\n",
    "The top 50% submissions will get 0-3 extra points. Try at least 3 models for each question. Try as many as you want for extra credit.\n",
    "<br><br>\n",
    "** Please do NOT distribute the dataset used in this assignment!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('D:/Dropbox/Teaching/Data Science using Python/Notebooks/Assignment5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predicting Gender with Username\n",
    "Some potential features of usernames: whether it has capital letters, whether it has digits, number of characters, number of vowels, first and last letters, etc. See http://www.nltk.org/book/ch06.html for some related code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(name):\n",
    "    name = name.lower()\n",
    "    features = {\n",
    "        'last': name[-1],\n",
    "        'last_two': name[-2:],\n",
    "        'last_three': name[-3:],\n",
    "        'first': name[0],\n",
    "        'first2': name[:1],\n",
    "        'first3': name[:2],\n",
    "        'nchar': len(name),\n",
    "        'vowels.pct': sum(c in 'aoeiu' for c in name)/len(name),\n",
    "        'digits.pct': sum(c.isdigit() for c in name)/len(name),\n",
    "        'endwd': name[-1].isdigit(),\n",
    "    }\n",
    "    # the features below do not seem to be useful\n",
    "    #for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        #features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_uname = [extract_features(row['username']) for idx, row in train.iterrows()]\n",
    "feat_uname_test = [extract_features(row['username']) for idx, row in test.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7456\n",
      "accuracy: 0.7416\n",
      "accuracy: 0.7488\n",
      "accuracy: 0.7344\n",
      "accuracy: 0.7365892714171337\n",
      "Final accuracy: 0.741397854283\n"
     ]
    }
   ],
   "source": [
    "method = ['SVM','NB','ME'][1]\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "accu = []\n",
    "Xy = list(zip(feat_uname, train['gender']))\n",
    "for train_idx, test_idx in k_fold.split(Xy):\n",
    "    train_obs = [Xy[i] for i in train_idx]\n",
    "    test_obs = [Xy[i] for i in test_idx]\n",
    "    if method == 'SVM':\n",
    "        classifier = SklearnClassifier(SVC(kernel='linear', C=1, random_state=1), sparse=True).train(train_obs)\n",
    "    if method == 'NB':\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_obs)\n",
    "    if method == 'ME':\n",
    "        classifier = nltk.classify.MaxentClassifier.train(train_obs, trace=3, max_iter=30)    \n",
    "    accu.append( nltk.classify.util.accuracy(classifier, test_obs) )\n",
    "    print('accuracy:', accu[len(accu)-1])    \n",
    "# select the best model based on CV performance shown below\n",
    "print('Final accuracy:', np.mean(accu))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (30 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.813\n",
      "             2          -0.34948        0.813\n",
      "             3          -0.33268        0.813\n",
      "             4          -0.31775        0.815\n",
      "             5          -0.30471        0.819\n",
      "             6          -0.29333        0.828\n",
      "             7          -0.28333        0.837\n",
      "             8          -0.27446        0.850\n",
      "             9          -0.26654        0.856\n",
      "            10          -0.25940        0.863\n",
      "            11          -0.25292        0.870\n",
      "            12          -0.24702        0.877\n",
      "            13          -0.24160        0.884\n",
      "            14          -0.23661        0.888\n",
      "            15          -0.23199        0.893\n",
      "            16          -0.22771        0.897\n",
      "            17          -0.22371        0.902\n",
      "            18          -0.21998        0.905\n",
      "            19          -0.21649        0.909\n",
      "            20          -0.21320        0.912\n",
      "            21          -0.21011        0.914\n",
      "            22          -0.20720        0.916\n",
      "            23          -0.20444        0.916\n",
      "            24          -0.20183        0.918\n",
      "            25          -0.19936        0.919\n",
      "            26          -0.19701        0.920\n",
      "            27          -0.19477        0.922\n",
      "            28          -0.19264        0.923\n",
      "            29          -0.19061        0.923\n",
      "         Final          -0.18867        0.924\n"
     ]
    }
   ],
   "source": [
    "clf_uname = nltk.classify.MaxentClassifier.train(Xy, trace=3, max_iter=30)\n",
    "pred_uname = [clf_uname.classify(row) for row in feat_uname_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# support your predictions are stored in a list named pred_uname\n",
    "zz = pd.DataFrame({'username':test['username'], 'prediction':pred_uname})\n",
    "zz.to_csv('pred_uname.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predicting Gender with Description\n",
    "The updated notebook for lecture 11 might be of some help, which now includes demo code for making predictions with NLTK classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "ps = PorterStemmer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "def preprocess(text):\n",
    "    return [ps.stem(w) for w in word_tokenize(text.lower()) \n",
    "             if w not in string.punctuation and w not in stopwords.words('english')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc_words = [preprocess(desc) for desc in train['description']]\n",
    "desc_words_test = [preprocess(desc) for desc in test['description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_words(words_2d_list, thd=1):\n",
    "    words = [word for desc in desc_words for word in desc]\n",
    "    words_freq = nltk.FreqDist(words)\n",
    "    selected_words = {word for word, freq in words_freq.items() if freq>1}\n",
    "    print('Before:',len(words_freq), ', after:', len(selected_words))\n",
    "    return selected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 36128 , after: 9953\n"
     ]
    }
   ],
   "source": [
    "selected_words = filter_words(desc_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(words, selected_words):\n",
    "    ''' simply using words counts'''\n",
    "    return nltk.FreqDist([w for w in words if w in selected_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_desc = [extract_features(desc, selected_words) for desc in desc_words]\n",
    "feat_desc_test = [extract_features(desc, selected_words) for desc in desc_words_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.564\n",
      "accuracy: 0.5544\n",
      "accuracy: 0.5696\n",
      "accuracy: 0.5896\n",
      "accuracy: 0.5468374699759808\n",
      "Final accuracy: 0.564887493995\n"
     ]
    }
   ],
   "source": [
    "method = ['SVM','NB','ME'][1]\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "accu = []\n",
    "Xy = list(zip(feat_desc, train['gender']))\n",
    "for train_idx, test_idx in k_fold.split(Xy):\n",
    "    train_obs = [Xy[i] for i in train_idx]\n",
    "    test_obs = [Xy[i] for i in test_idx]\n",
    "    if method == 'SVM':\n",
    "        classifier = SklearnClassifier(SVC(kernel='linear', C=1, random_state=1), sparse=True).train(train_obs)\n",
    "    if method == 'NB':\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_obs)\n",
    "    if method == 'ME':\n",
    "        classifier = nltk.classify.MaxentClassifier.train(train_obs, trace=3, max_iter=30)    \n",
    "    accu.append( nltk.classify.util.accuracy(classifier, test_obs) )\n",
    "    print('accuracy:', accu[len(accu)-1])    \n",
    "# select the best model based on CV performance shown below\n",
    "print('Final accuracy:', np.mean(accu))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predicting Gender with Username, Description, and Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse Json format status as dictionary\n",
    "from ast import literal_eval\n",
    "status = train['status'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find a way to expand/split the status column as multiple columns\n",
    "status_ext = status.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_status = status_ext.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status_test_ext = test['status'].apply(literal_eval).apply(pd.Series)\n",
    "feat_status_test = status_test_ext.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_all = [{**a, **b, **c} for a,b,c in zip(feat_uname, feat_desc, feat_status)]\n",
    "feat_all_test = [{**a, **b, **c} for a,b,c in zip(feat_uname_test, feat_desc_test, feat_status_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5984\n",
      "accuracy: 0.5304\n",
      "accuracy: 0.6128\n",
      "accuracy: 0.5704\n",
      "accuracy: 0.6020816653322658\n",
      "Final accuracy: 0.582816333066\n"
     ]
    }
   ],
   "source": [
    "method = ['SVM','NB','ME'][1]\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "accu = []\n",
    "Xy = list(zip(feat_all, train['gender']))\n",
    "for train_idx, test_idx in k_fold.split(Xy):\n",
    "    train_obs = [Xy[i] for i in train_idx]\n",
    "    test_obs = [Xy[i] for i in test_idx]\n",
    "    if method == 'SVM':\n",
    "        classifier = SklearnClassifier(SVC(kernel='linear', C=1, random_state=1), sparse=True).train(train_obs)\n",
    "    if method == 'NB':\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_obs)\n",
    "    if method == 'ME':\n",
    "        classifier = nltk.classify.MaxentClassifier.train(train_obs, trace=3, max_iter=30)    \n",
    "    accu.append( nltk.classify.util.accuracy(classifier, test_obs) )\n",
    "    print('accuracy:', accu[len(accu)-1])    \n",
    "# select the best model based on CV performance shown below\n",
    "print('Final accuracy:', np.mean(accu))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Try Different Features and Models for Best Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = nltk.classify.NaiveBayesClassifier.train(Xy)\n",
    "pred = [clf.classify(row) for row in feat_all_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zz = pd.DataFrame({'username':test['username'], 'prediction':pred_uname})\n",
    "zz.to_csv('pred_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
